{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, cross_val_score\n",
    "from sklearn.metrics import *\n",
    "from scipy.stats import randint\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(3),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    BalancedRandomForestClassifier(),\n",
    "    RUSBoostClassifier()\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2020\n",
    "\n",
    "for year in range(start, 2022):\n",
    "    year = str(year)\n",
    "    df = pd.read_csv('years/'+year+'.csv')\n",
    "    df2 = pd.read_csv('random_sample/'+year+'.csv')\n",
    "    artist_id = pd.read_csv('artist_weeks_data.csv')\n",
    "    if 'df3' not in globals():\n",
    "        df3 = df.append(df2)\n",
    "    else:\n",
    "        df3 = df3.append(df)\n",
    "        df3 = df3.append(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(artist_id['artist'])\n",
    "values = list(artist_id['artist_id'])\n",
    "artist_id = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = []\n",
    "arr = df3['spotify_artist'].to_numpy().astype(str)\n",
    "arr = np.char.rstrip(arr, \"']\")\n",
    "arr = np.char.lstrip(arr, \"['\")\n",
    "arr = np.char.split(arr, \"', '\")\n",
    "for i, a_list in enumerate(arr):\n",
    "    if a_list[0] in artist_id:\n",
    "        artist.append(artist_id[a_list[0]])\n",
    "    else:\n",
    "        artist_id[a_list[0]] = len(artist_id) + 1\n",
    "        artist.append(artist_id[a_list[0]])\n",
    "df3['spotify_id'] = artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = df3.iloc[:,6:].to_numpy()\n",
    "X = Xy[:, :-2]\n",
    "y = Xy[:,-1]\n",
    "label = y.copy()\n",
    "label[y <= 0] = 0\n",
    "label[y > 0] = 1\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "max_test = \"\"\n",
    "for clf in classifiers:\n",
    "    print(\"=\"*30)\n",
    "    name = clf.__class__.__name__\n",
    "    print(name)\n",
    "    score = cross_validate(clf, X, y, scoring=['f1', 'precision', 'recall', 'accuracy', 'roc_auc'], n_jobs = -1, cv = 10)\n",
    "\n",
    "    print(\"Accuracy: {:.4%}\".format(np.mean(score['test_accuracy'])))\n",
    "    print(\"F1: {:.4%}\".format(np.mean(score['test_f1'])))\n",
    "    print(\"Recall: {:.4%}\".format(np.mean(score['test_recall'])))\n",
    "    print(\"Precision: {:.4%}\".format(np.mean(score['test_precision'])))\n",
    "    print(\"AUC: {:.4%}\".format(np.mean(score['test_roc_auc'])))\n",
    "\n",
    "    if np.mean(score['test_f1']) > max_score:\n",
    "        max_score = np.mean(score['test_roc_auc'])\n",
    "        max_test = clf.__class__.__name__\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = pd.DataFrame(columns = ['accuracy', 'recall', 'precision'])\n",
    "for i in range(1980, 2022):\n",
    "    year = i\n",
    "\n",
    "\n",
    "    year = str(year)\n",
    "    df = pd.read_csv('with_number_of_weeks/years/'+year+'.csv')\n",
    "    df2 = pd.read_csv('random_sample/'+year+'.csv')\n",
    "    artist_id = pd.read_csv('artist_weeks_data.csv')\n",
    "    df3 = df.append(df2)\n",
    "\n",
    "    keys = list(artist_id['artist'])\n",
    "    values = list(artist_id['artist_id'])\n",
    "    artist_id = dict(zip(keys, values))\n",
    "\n",
    "    artist = []\n",
    "    arr = df3['spotify_artist'].to_numpy().astype(str)\n",
    "    arr = np.char.rstrip(arr, \"']\")\n",
    "    arr = np.char.lstrip(arr, \"['\")\n",
    "    arr = np.char.split(arr, \"', '\")\n",
    "    for i, a_list in enumerate(arr):\n",
    "        if a_list[0] in artist_id:\n",
    "            artist.append(artist_id[a_list[0]])\n",
    "        else:\n",
    "            artist_id[a_list[0]] = len(artist_id) + 1\n",
    "            artist.append(artist_id[a_list[0]])\n",
    "    df3['spotify_id'] = artist\n",
    "\n",
    "    Xy = df3.iloc[:,6:].to_numpy()\n",
    "    X = Xy[:, :-2]\n",
    "    y = Xy[:,-1]\n",
    "    label = y.copy()\n",
    "    label[y <= 0] = 0\n",
    "    label[y > 0] = 1\n",
    "    y = label\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    clf = RandomForestClassifier()\n",
    "    # clf.fit(X_train, y_train)\n",
    "    score = cross_validate(clf, X, y, scoring=['f1', 'precision', 'recall', 'accuracy', 'roc_auc'], n_jobs = -1, cv = 10)\n",
    "    scores = [score['test_accuracy'], score['test_recall'], score['test_precision']]\n",
    "    scores = np.mean(scores, axis = 1)\n",
    "    ml_df = ml_df.append(pd.DataFrame(list(scores.reshape(1,3)), columns = ['accuracy', 'recall', 'precision']))\n",
    "\n",
    "    # pickle.dump(clf, open('ml_models/' + year + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7645569620253164"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_model = pickle.load(open('ml_models/2021.pkl', 'rb'))\n",
    "np.sum(pk_model.predict(X_test) == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.72334</td>\n",
       "      <td>0.816131</td>\n",
       "      <td>0.685762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy    recall  precision\n",
       "0   0.72334  0.816131   0.685762"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(scores.reshape(1,3)), columns = ['accuracy', 'recall', 'precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df.to_csv(\"ml_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "703e297788ae86296449f676e0241f89b67adc670f29c8299b77ab5d7193a91f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('music': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
